# roughness_iconicity
## Project by Bodo Winter, Marton Soskuthy, Marcus Perlman and Mark Dingemanse

### Scripts

- preprocessing_english_pronunciations.R
- libraries.R
- phoneme_extraction.R
- mantel_tests.R
- random_forests.R
- baseline_lexicon.R

## Datasets

- stadtlander_roughness_norms.csv
- ELP_pronunciations.csv
- SUBTLEX_POS.csv
- wedel_english_phoneme_freq.xlsx

## To-do list:

- clean scripts and add existing set of Indo-European results and etymology results
- check validity of Google translations with Hungarian norms
- replicate analyses for Hungarian
- perform random forests on onsets, codas, full syllables etc.
- perform Mantel tests on full words and go from left to right (old analysis)
- onset cluster consonant density / syllable complexity? (Marton's idea?)
- Levenshtein distance controlling for length? (not much of a concern since we only focus on the same syllable)
- add Mark's African languages
- add world's languages? (IDS + Phoible)
- phoneme features?
- nonce word experiments?

